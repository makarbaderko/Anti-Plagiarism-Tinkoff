Module(body=[ImportFrom(module='typing', names=[alias(name='Any')], level=0), ImportFrom(module='typing', names=[alias(name='Dict')], level=0), ImportFrom(module='typing', names=[alias(name='List')], level=0), ImportFrom(module='typing', names=[alias(name='Optional')], level=0), ImportFrom(module='typing', names=[alias(name='Sequence')], level=0), ImportFrom(module='typing', names=[alias(name='Union')], level=0), Import(names=[alias(name='pandas', asname='pd')]), ImportFrom(module='etna', names=[alias(name='SETTINGS')], level=0), ImportFrom(module='etna.datasets.tsdataset', names=[alias(name='TSDataset')], level=0), ImportFrom(module='etna.loggers', names=[alias(name='tslogger')], level=0), ImportFrom(module='etna.models.base', names=[alias(name='PredictionIntervalContextIgnorantAbstractModel')], level=0), ImportFrom(module='etna.models.base', names=[alias(name='log_decorator')], level=0), ImportFrom(module='etna.models.nn.utils', names=[alias(name='_DeepCopyMixin')], level=0), ImportFrom(module='etna.transforms', names=[alias(name='PytorchForecastingTransform')], level=0), If(test=Attribute(value=Name(id='SETTINGS', ctx=Load()), attr='torch_required', ctx=Load()), body=[Import(names=[alias(name='pytorch_lightning', asname='pl')]), ImportFrom(module='pytorch_forecasting.data', names=[alias(name='TimeSeriesDataSet')], level=0), ImportFrom(module='pytorch_forecasting.metrics', names=[alias(name='DistributionLoss')], level=0), ImportFrom(module='pytorch_forecasting.metrics', names=[alias(name='NormalDistributionLoss')], level=0), ImportFrom(module='pytorch_forecasting.models', names=[alias(name='DeepAR')], level=0), ImportFrom(module='pytorch_lightning', names=[alias(name='LightningModule')], level=0)], orelse=[]), ClassDef(name='DeepARModel', bases=[Name(id='_DeepCopyMixin', ctx=Load()), Name(id='PredictionIntervalContextIgnorantAbstractModel', ctx=Load())], keywords=[], body=[Expr(value=Constant(value='Wrapper for :py:class:`pytorch_forecasting.models.deepar.DeepAR`.\n\n    Notes\n    -----\n    We save :py:class:`pytorch_forecasting.data.timeseries.TimeSeriesDataSet` in instance to use it in the model.\n    It`s not right pattern of using Transforms and TSDataset.\n    ')), Assign(targets=[Name(id='context_size', ctx=Store())], value=Constant(value=0)), FunctionDef(name='__init__', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='batch_size', annotation=Name(id='int', ctx=Load())), arg(arg='context_length', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Name(id='int', ctx=Load()), ctx=Load())), arg(arg='max_epochs', annotation=Name(id='int', ctx=Load())), arg(arg='gpus', annotation=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='int', ctx=Load()), Subscript(value=Name(id='List', ctx=Load()), slice=Name(id='int', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load())), arg(arg='gradient_clip_val', annotation=Name(id='float', ctx=Load())), arg(arg='learning_rate', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Subscript(value=Name(id='List', ctx=Load()), slice=Name(id='float', ctx=Load()), ctx=Load()), ctx=Load())), arg(arg='cell_type', annotation=Name(id='str', ctx=Load())), arg(arg='hidden_size', annotation=Name(id='int', ctx=Load())), arg(arg='rnn_layers', annotation=Name(id='int', ctx=Load())), arg(arg='dropout', annotation=Name(id='float', ctx=Load())), arg(arg='loss', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Constant(value='DistributionLoss'), ctx=Load())), arg(arg='trainer_kwargs', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Subscript(value=Name(id='Dict', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Name(id='Any', ctx=Load())], ctx=Load()), ctx=Load()), ctx=Load())), arg(arg='quantiles_kwargs', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Subscript(value=Name(id='Dict', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Name(id='Any', ctx=Load())], ctx=Load()), ctx=Load()), ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=64), Constant(value=None), Constant(value=10), Constant(value=0), Constant(value=0.1), Constant(value=None), Constant(value='LSTM'), Constant(value=10), Constant(value=2), Constant(value=0.1), Constant(value=None), Constant(value=None), Constant(value=None)]), body=[Expr(value=Constant(value="\n        Initialize DeepAR wrapper.\n\n        Parameters\n        ----------\n        batch_size:\n            Batch size.\n        context_length:\n            Max encoder length, if None max encoder length is equal to 2 horizons.\n        max_epochs:\n            Max epochs.\n        gpus:\n            0 - is CPU, or [n_{i}] - to choose n_{i} GPU from cluster.\n        gradient_clip_val:\n            Clipping by norm is using, choose 0 to not clip.\n        learning_rate:\n            Learning rate.\n        cell_type:\n            One of 'LSTM', 'GRU'.\n        hidden_size:\n            Hidden size of network which can range from 8 to 512.\n        rnn_layers:\n            Number of LSTM layers.\n        dropout:\n            Dropout rate.\n        loss:\n            Distribution loss function. Keep in mind that each distribution\n            loss function might have specific requirements for target normalization.\n            Defaults to :py:class:`pytorch_forecasting.metrics.NormalDistributionLoss`.\n        trainer_kwargs:\n            Additional arguments for pytorch_lightning Trainer.\n        quantiles_kwargs:\n            Additional arguments for computing quantiles, look at ``to_quantiles()`` method for your loss.\n        ")), Expr(value=Call(func=Attribute(value=Call(func=Name(id='super', ctx=Load()), args=[], keywords=[]), attr='__init__', ctx=Load()), args=[], keywords=[])), If(test=Compare(left=Name(id='loss', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=[Assign(targets=[Name(id='loss', ctx=Store())], value=Call(func=Name(id='NormalDistributionLoss', ctx=Load()), args=[], keywords=[]))], orelse=[]), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='max_epochs', ctx=Store())], value=Name(id='max_epochs', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='gpus', ctx=Store())], value=Name(id='gpus', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='gradient_clip_val', ctx=Store())], value=Name(id='gradient_clip_val', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='learning_rate', ctx=Store())], value=IfExp(test=Compare(left=Name(id='learning_rate', ctx=Load()), ops=[IsNot()], comparators=[Constant(value=None)]), body=Name(id='learning_rate', ctx=Load()), orelse=List(elts=[Constant(value=0.001)], ctx=Load()))), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='batch_size', ctx=Store())], value=Name(id='batch_size', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='context_length', ctx=Store())], value=Name(id='context_length', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='cell_type', ctx=Store())], value=Name(id='cell_type', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='hidden_size', ctx=Store())], value=Name(id='hidden_size', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='rnn_layers', ctx=Store())], value=Name(id='rnn_layers', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='dropout', ctx=Store())], value=Name(id='dropout', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='loss', ctx=Store())], value=Name(id='loss', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='trainer_kwargs', ctx=Store())], value=IfExp(test=Compare(left=Name(id='trainer_kwargs', ctx=Load()), ops=[IsNot()], comparators=[Constant(value=None)]), body=Name(id='trainer_kwargs', ctx=Load()), orelse=Call(func=Name(id='dict', ctx=Load()), args=[], keywords=[]))), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='quantiles_kwargs', ctx=Store())], value=IfExp(test=Compare(left=Name(id='quantiles_kwargs', ctx=Load()), ops=[IsNot()], comparators=[Constant(value=None)]), body=Name(id='quantiles_kwargs', ctx=Load()), orelse=Call(func=Name(id='dict', ctx=Load()), args=[], keywords=[]))), AnnAssign(target=Attribute(value=Name(id='self', ctx=Load()), attr='model', ctx=Store()), annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='LightningModule', ctx=Load()), Name(id='DeepAR', ctx=Load())], ctx=Load()), ctx=Load()), ctx=Load()), value=Constant(value=None), simple=0), AnnAssign(target=Attribute(value=Name(id='self', ctx=Load()), attr='trainer', ctx=Store()), annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Attribute(value=Name(id='pl', ctx=Load()), attr='Trainer', ctx=Load()), ctx=Load()), value=Constant(value=None), simple=0), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='_last_train_timestamp', ctx=Store())], value=Constant(value=None)), AnnAssign(target=Attribute(value=Name(id='self', ctx=Load()), attr='_freq', ctx=Store()), annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Name(id='str', ctx=Load()), ctx=Load()), value=Constant(value=None), simple=0)], decorator_list=[]), FunctionDef(name='_from_dataset', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='ts_dataset', annotation=Name(id='TimeSeriesDataSet', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\n        Construct DeepAR.\n\n        Returns\n        -------\n        DeepAR\n            Class instance.\n        ')), Return(value=Call(func=Attribute(value=Name(id='DeepAR', ctx=Load()), attr='from_dataset', ctx=Load()), args=[Name(id='ts_dataset', ctx=Load())], keywords=[keyword(arg='learning_rate', value=Attribute(value=Name(id='self', ctx=Load()), attr='learning_rate', ctx=Load())), keyword(arg='cell_type', value=Attribute(value=Name(id='self', ctx=Load()), attr='cell_type', ctx=Load())), keyword(arg='hidden_size', value=Attribute(value=Name(id='self', ctx=Load()), attr='hidden_size', ctx=Load())), keyword(arg='rnn_layers', value=Attribute(value=Name(id='self', ctx=Load()), attr='rnn_layers', ctx=Load())), keyword(arg='dropout', value=Attribute(value=Name(id='self', ctx=Load()), attr='dropout', ctx=Load())), keyword(arg='loss', value=Attribute(value=Name(id='self', ctx=Load()), attr='loss', ctx=Load()))]))], decorator_list=[], returns=Name(id='LightningModule', ctx=Load())), FunctionDef(name='_get_pf_transform', args=arguments(posonlyargs=[], args=[arg(arg='ts', annotation=Name(id='TSDataset', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='Get PytorchForecastingTransform from ts.transforms or raise exception if not found.')), If(test=BoolOp(op=And(), values=[Compare(left=Attribute(value=Name(id='ts', ctx=Load()), attr='transforms', ctx=Load()), ops=[IsNot()], comparators=[Constant(value=None)]), Call(func=Name(id='isinstance', ctx=Load()), args=[Subscript(value=Attribute(value=Name(id='ts', ctx=Load()), attr='transforms', ctx=Load()), slice=UnaryOp(op=USub(), operand=Constant(value=1)), ctx=Load()), Name(id='PytorchForecastingTransform', ctx=Load())], keywords=[])]), body=[Return(value=Subscript(value=Attribute(value=Name(id='ts', ctx=Load()), attr='transforms', ctx=Load()), slice=UnaryOp(op=USub(), operand=Constant(value=1)), ctx=Load()))], orelse=[Raise(exc=Call(func=Name(id='ValueError', ctx=Load()), args=[Constant(value='Not valid usage of transforms, please add PytorchForecastingTransform at the end of transforms')], keywords=[]))])], decorator_list=[Name(id='staticmethod', ctx=Load())], returns=Name(id='PytorchForecastingTransform', ctx=Load())), FunctionDef(name='fit', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='ts', annotation=Name(id='TSDataset', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\n        Fit model.\n\n        Parameters\n        ----------\n        ts:\n            TSDataset to fit.\n\n        Returns\n        -------\n        DeepARModel\n        ')), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='_last_train_timestamp', ctx=Store())], value=Subscript(value=Attribute(value=Attribute(value=Name(id='ts', ctx=Load()), attr='df', ctx=Load()), attr='index', ctx=Load()), slice=UnaryOp(op=USub(), operand=Constant(value=1)), ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='_freq', ctx=Store())], value=Attribute(value=Name(id='ts', ctx=Load()), attr='freq', ctx=Load())), Assign(targets=[Name(id='pf_transform', ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='_get_pf_transform', ctx=Load()), args=[Name(id='ts', ctx=Load())], keywords=[])), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='model', ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='_from_dataset', ctx=Load()), args=[Attribute(value=Name(id='pf_transform', ctx=Load()), attr='pf_dataset_train', ctx=Load())], keywords=[])), Assign(targets=[Name(id='trainer_kwargs', ctx=Store())], value=Call(func=Name(id='dict', ctx=Load()), args=[], keywords=[keyword(arg='logger', value=Attribute(value=Name(id='tslogger', ctx=Load()), attr='pl_loggers', ctx=Load())), keyword(arg='max_epochs', value=Attribute(value=Name(id='self', ctx=Load()), attr='max_epochs', ctx=Load())), keyword(arg='gpus', value=Attribute(value=Name(id='self', ctx=Load()), attr='gpus', ctx=Load())), keyword(arg='gradient_clip_val', value=Attribute(value=Name(id='self', ctx=Load()), attr='gradient_clip_val', ctx=Load()))])), Expr(value=Call(func=Attribute(value=Name(id='trainer_kwargs', ctx=Load()), attr='update', ctx=Load()), args=[Attribute(value=Name(id='self', ctx=Load()), attr='trainer_kwargs', ctx=Load())], keywords=[])), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='trainer', ctx=Store())], value=Call(func=Attribute(value=Name(id='pl', ctx=Load()), attr='Trainer', ctx=Load()), args=[], keywords=[keyword(value=Name(id='trainer_kwargs', ctx=Load()))])), Assign(targets=[Name(id='train_dataloader', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='pf_transform', ctx=Load()), attr='pf_dataset_train', ctx=Load()), attr='to_dataloader', ctx=Load()), args=[], keywords=[keyword(arg='train', value=Constant(value=True)), keyword(arg='batch_size', value=Attribute(value=Name(id='self', ctx=Load()), attr='batch_size', ctx=Load()))])), Expr(value=Call(func=Attribute(value=Attribute(value=Name(id='self', ctx=Load()), attr='trainer', ctx=Load()), attr='fit', ctx=Load()), args=[Attribute(value=Name(id='self', ctx=Load()), attr='model', ctx=Load()), Name(id='train_dataloader', ctx=Load())], keywords=[])), Return(value=Name(id='self', ctx=Load()))], decorator_list=[Name(id='log_decorator', ctx=Load())], returns=Constant(value='DeepARModel')), FunctionDef(name='forecast', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='ts', annotation=Name(id='TSDataset', ctx=Load())), arg(arg='prediction_interval', annotation=Name(id='bool', ctx=Load())), arg(arg='quantiles', annotation=Subscript(value=Name(id='Sequence', ctx=Load()), slice=Name(id='float', ctx=Load()), ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=False), Tuple(elts=[Constant(value=0.025), Constant(value=0.975)], ctx=Load())]), body=[Expr(value=Constant(value='Make predictions.\n\n        This method will make autoregressive predictions.\n\n        Parameters\n        ----------\n        ts:\n            Dataset with features\n        prediction_interval:\n            If True returns prediction interval for forecast\n        quantiles:\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\n\n        Returns\n        -------\n        TSDataset\n            TSDataset with predictions.\n        ')), If(test=Compare(left=Subscript(value=Attribute(value=Name(id='ts', ctx=Load()), attr='index', ctx=Load()), slice=Constant(value=0), ctx=Load()), ops=[LtE()], comparators=[Attribute(value=Name(id='self', ctx=Load()), attr='_last_train_timestamp', ctx=Load())]), body=[Raise(exc=Call(func=Name(id='NotImplementedError', ctx=Load()), args=[Constant(value="It is not possible to make in-sample predictions with DeepAR model! In-sample predictions aren't supported by current implementation.")], keywords=[]))], orelse=[If(test=Compare(left=Subscript(value=Attribute(value=Name(id='ts', ctx=Load()), attr='index', ctx=Load()), slice=Constant(value=0), ctx=Load()), ops=[NotEq()], comparators=[Subscript(value=Call(func=Attribute(value=Name(id='pd', ctx=Load()), attr='date_range', ctx=Load()), args=[Attribute(value=Name(id='self', ctx=Load()), attr='_last_train_timestamp', ctx=Load())], keywords=[keyword(arg='periods', value=Constant(value=2)), keyword(arg='freq', value=Attribute(value=Name(id='self', ctx=Load()), attr='_freq', ctx=Load()))]), slice=UnaryOp(op=USub(), operand=Constant(value=1)), ctx=Load())]), body=[Raise(exc=Call(func=Name(id='NotImplementedError', ctx=Load()), args=[JoinedStr(values=[Constant(value='You can only forecast from the next point after the last one in the training dataset: last train timestamp: '), FormattedValue(value=Attribute(value=Name(id='self', ctx=Load()), attr='_last_train_timestamp', ctx=Load()), conversion=-1), Constant(value=', first test timestamp is '), FormattedValue(value=Subscript(value=Attribute(value=Name(id='ts', ctx=Load()), attr='index', ctx=Load()), slice=Constant(value=0), ctx=Load()), conversion=-1)])], keywords=[]))], orelse=[Pass()])]), Assign(targets=[Name(id='pf_transform', ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='_get_pf_transform', ctx=Load()), args=[Name(id='ts', ctx=Load())], keywords=[])), If(test=Compare(left=Attribute(value=Name(id='pf_transform', ctx=Load()), attr='pf_dataset_predict', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=[Raise(exc=Call(func=Name(id='ValueError', ctx=Load()), args=[Constant(value='The future is not generated! Generate future using TSDataset make_future before calling forecast method!')], keywords=[]))], orelse=[]), Assign(targets=[Name(id='prediction_dataloader', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='pf_transform', ctx=Load()), attr='pf_dataset_predict', ctx=Load()), attr='to_dataloader', ctx=Load()), args=[], keywords=[keyword(arg='train', value=Constant(value=False)), keyword(arg='batch_size', value=BinOp(left=Attribute(value=Name(id='self', ctx=Load()), attr='batch_size', ctx=Load()), op=Mult(), right=Constant(value=2)))])), Assign(targets=[Name(id='predicts', ctx=Store())], value=Call(func=Attribute(value=Call(func=Attribute(value=Attribute(value=Name(id='self', ctx=Load()), attr='model', ctx=Load()), attr='predict', ctx=Load()), args=[Name(id='prediction_dataloader', ctx=Load())], keywords=[]), attr='numpy', ctx=Load()), args=[], keywords=[])), Assign(targets=[Subscript(value=Attribute(value=Name(id='ts', ctx=Load()), attr='loc', ctx=Load()), slice=Tuple(elts=[Slice(), Subscript(value=Attribute(value=Name(id='pd', ctx=Load()), attr='IndexSlice', ctx=Load()), slice=Tuple(elts=[Slice(), Constant(value='target')], ctx=Load()), ctx=Load())], ctx=Load()), ctx=Store())], value=Subscript(value=Attribute(value=Name(id='predicts', ctx=Load()), attr='T', ctx=Load()), slice=Slice(upper=Call(func=Name(id='len', ctx=Load()), args=[Attribute(value=Name(id='ts', ctx=Load()), attr='df', ctx=Load())], keywords=[])), ctx=Load())), If(test=Name(id='prediction_interval', ctx=Load()), body=[Assign(targets=[Name(id='quantiles_predicts', ctx=Store())], value=Call(func=Attribute(value=Call(func=Attribute(value=Attribute(value=Name(id='self', ctx=Load()), attr='model', ctx=Load()), attr='predict', ctx=Load()), args=[Name(id='prediction_dataloader', ctx=Load())], keywords=[keyword(arg='mode', value=Constant(value='quantiles')), keyword(arg='mode_kwargs', value=Dict(keys=[Constant(value='quantiles'), None], values=[Name(id='quantiles', ctx=Load()), Attribute(value=Name(id='self', ctx=Load()), attr='quantiles_kwargs', ctx=Load())]))]), attr='numpy', ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id='quantiles_predicts', ctx=Store())], value=Call(func=Attribute(value=Name(id='quantiles_predicts', ctx=Load()), attr='transpose', ctx=Load()), args=[Tuple(elts=[Constant(value=1), Constant(value=0), Constant(value=2)], ctx=Load())], keywords=[])), Assign(targets=[Name(id='quantiles_predicts', ctx=Store())], value=Call(func=Attribute(value=Name(id='quantiles_predicts', ctx=Load()), attr='reshape', ctx=Load()), args=[Subscript(value=Attribute(value=Name(id='quantiles_predicts', ctx=Load()), attr='shape', ctx=Load()), slice=Constant(value=0), ctx=Load()), UnaryOp(op=USub(), operand=Constant(value=1))], keywords=[])), Assign(targets=[Name(id='df', ctx=Store())], value=Attribute(value=Name(id='ts', ctx=Load()), attr='df', ctx=Load())), Assign(targets=[Name(id='segments', ctx=Store())], value=Attribute(value=Name(id='ts', ctx=Load()), attr='segments', ctx=Load())), Assign(targets=[Name(id='quantile_columns', ctx=Store())], value=ListComp(elt=JoinedStr(values=[Constant(value='target_'), FormattedValue(value=Name(id='quantile', ctx=Load()), conversion=-1, format_spec=JoinedStr(values=[Constant(value='.4g')]))]), generators=[comprehension(target=Name(id='quantile', ctx=Store()), iter=Name(id='quantiles', ctx=Load()), ifs=[], is_async=0)])), Assign(targets=[Name(id='columns', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='pd', ctx=Load()), attr='MultiIndex', ctx=Load()), attr='from_product', ctx=Load()), args=[List(elts=[Name(id='segments', ctx=Load()), Name(id='quantile_columns', ctx=Load())], ctx=Load())], keywords=[])), Assign(targets=[Name(id='quantiles_df', ctx=Store())], value=Call(func=Attribute(value=Name(id='pd', ctx=Load()), attr='DataFrame', ctx=Load()), args=[Subscript(value=Name(id='quantiles_predicts', ctx=Load()), slice=Slice(upper=Call(func=Name(id='len', ctx=Load()), args=[Name(id='df', ctx=Load())], keywords=[])), ctx=Load())], keywords=[keyword(arg='columns', value=Name(id='columns', ctx=Load())), keyword(arg='index', value=Attribute(value=Name(id='df', ctx=Load()), attr='index', ctx=Load()))])), Assign(targets=[Name(id='df', ctx=Store())], value=Call(func=Attribute(value=Name(id='pd', ctx=Load()), attr='concat', ctx=Load()), args=[Tuple(elts=[Name(id='df', ctx=Load()), Name(id='quantiles_df', ctx=Load())], ctx=Load())], keywords=[keyword(arg='axis', value=Constant(value=1))])), Assign(targets=[Name(id='df', ctx=Store())], value=Call(func=Attribute(value=Name(id='df', ctx=Load()), attr='sort_index', ctx=Load()), args=[], keywords=[keyword(arg='axis', value=Constant(value=1))])), Assign(targets=[Attribute(value=Name(id='ts', ctx=Load()), attr='df', ctx=Store())], value=Name(id='df', ctx=Load()))], orelse=[]), Expr(value=Call(func=Attribute(value=Name(id='ts', ctx=Load()), attr='inverse_transform', ctx=Load()), args=[], keywords=[])), Return(value=Name(id='ts', ctx=Load()))], decorator_list=[Name(id='log_decorator', ctx=Load())], returns=Name(id='TSDataset', ctx=Load())), FunctionDef(name='predict', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='ts', annotation=Name(id='TSDataset', ctx=Load())), arg(arg='prediction_interval', annotation=Name(id='bool', ctx=Load())), arg(arg='quantiles', annotation=Subscript(value=Name(id='Sequence', ctx=Load()), slice=Name(id='float', ctx=Load()), ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=False), Tuple(elts=[Constant(value=0.025), Constant(value=0.975)], ctx=Load())]), body=[Expr(value=Constant(value='Make predictions.\n\n        This method will make predictions using true values instead of predicted on a previous step.\n        It can be useful for making in-sample forecasts.\n\n        Parameters\n        ----------\n        ts:\n            Dataset with features\n        prediction_interval:\n            If True returns prediction interval for forecast\n        quantiles:\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\n\n        Returns\n        -------\n        TSDataset\n            TSDataset with predictions.\n        ')), Raise(exc=Call(func=Name(id='NotImplementedError', ctx=Load()), args=[Constant(value="Method predict isn't currently implemented!")], keywords=[]))], decorator_list=[Name(id='log_decorator', ctx=Load())], returns=Name(id='TSDataset', ctx=Load())), FunctionDef(name='get_model', args=arguments(posonlyargs=[], args=[arg(arg='self')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='Get internal model that is used inside etna class.\n\n        Internal model is a model that is used inside etna to forecast segments,\n        e.g. :py:class:`catboost.CatBoostRegressor` or :py:class:`sklearn.linear_model.Ridge`.\n\n        Returns\n        -------\n        :\n           Internal model\n        ')), Return(value=Attribute(value=Name(id='self', ctx=Load()), attr='model', ctx=Load()))], decorator_list=[], returns=Name(id='Any', ctx=Load()))], decorator_list=[])], type_ignores=[])