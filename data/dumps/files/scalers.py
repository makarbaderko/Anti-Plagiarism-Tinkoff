Module(body=[ImportFrom(module='typing', names=[alias(name='List')], level=0), ImportFrom(module='typing', names=[alias(name='Optional')], level=0), ImportFrom(module='typing', names=[alias(name='Tuple')], level=0), ImportFrom(module='typing', names=[alias(name='Union')], level=0), ImportFrom(module='sklearn.preprocessing', names=[alias(name='MaxAbsScaler')], level=0), ImportFrom(module='sklearn.preprocessing', names=[alias(name='MinMaxScaler')], level=0), ImportFrom(module='sklearn.preprocessing', names=[alias(name='RobustScaler')], level=0), ImportFrom(module='sklearn.preprocessing', names=[alias(name='StandardScaler')], level=0), ImportFrom(module='etna.transforms.math.sklearn', names=[alias(name='SklearnTransform')], level=0), ImportFrom(module='etna.transforms.math.sklearn', names=[alias(name='TransformMode')], level=0), ClassDef(name='StandardScalerTransform', bases=[Name(id='SklearnTransform', ctx=Load())], keywords=[], body=[Expr(value=Constant(value='Standardize features by removing the mean and scaling to unit variance.\n\n    Uses :py:class:`sklearn.preprocessing.StandardScaler` inside.\n\n    Warning\n    -------\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\n    it uses information from the whole train part.\n    ')), FunctionDef(name='__init__', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='in_column', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Subscript(value=Name(id='List', ctx=Load()), slice=Name(id='str', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load()), ctx=Load())), arg(arg='inplace', annotation=Name(id='bool', ctx=Load())), arg(arg='out_column', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Name(id='str', ctx=Load()), ctx=Load())), arg(arg='with_mean', annotation=Name(id='bool', ctx=Load())), arg(arg='with_std', annotation=Name(id='bool', ctx=Load())), arg(arg='mode', annotation=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='TransformMode', ctx=Load()), Name(id='str', ctx=Load())], ctx=Load()), ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=None), Constant(value=True), Constant(value=None), Constant(value=True), Constant(value=True), Constant(value='per-segment')]), body=[Expr(value=Constant(value='\n        Init StandardScalerPreprocess.\n\n        Parameters\n        ----------\n        in_column:\n            columns to be scaled, if None - all columns will be scaled.\n        inplace:\n            features are changed by scaled.\n        out_column:\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\n        with_mean:\n            if True, center the data before scaling.\n        with_std:\n            if True, scale the data to unit standard deviation.\n        mode:\n            "macro" or "per-segment", way to transform features over segments.\n\n            * If "macro", transforms features globally, gluing the corresponding ones for all segments.\n\n            * If "per-segment", transforms features for each segment separately.\n\n        Raises\n        ------\n        ValueError:\n            if incorrect mode given\n        ')), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='with_mean', ctx=Store())], value=Name(id='with_mean', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='with_std', ctx=Store())], value=Name(id='with_std', ctx=Load())), Expr(value=Call(func=Attribute(value=Call(func=Name(id='super', ctx=Load()), args=[], keywords=[]), attr='__init__', ctx=Load()), args=[], keywords=[keyword(arg='in_column', value=Name(id='in_column', ctx=Load())), keyword(arg='transformer', value=Call(func=Name(id='StandardScaler', ctx=Load()), args=[], keywords=[keyword(arg='with_mean', value=Attribute(value=Name(id='self', ctx=Load()), attr='with_mean', ctx=Load())), keyword(arg='with_std', value=Attribute(value=Name(id='self', ctx=Load()), attr='with_std', ctx=Load())), keyword(arg='copy', value=Constant(value=True))])), keyword(arg='out_column', value=Name(id='out_column', ctx=Load())), keyword(arg='inplace', value=Name(id='inplace', ctx=Load())), keyword(arg='mode', value=Name(id='mode', ctx=Load()))]))], decorator_list=[])], decorator_list=[]), ClassDef(name='RobustScalerTransform', bases=[Name(id='SklearnTransform', ctx=Load())], keywords=[], body=[Expr(value=Constant(value='Scale features using statistics that are robust to outliers.\n\n    Uses :py:class:`sklearn.preprocessing.RobustScaler` inside.\n\n    Warning\n    -------\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\n    it uses information from the whole train part.\n    ')), FunctionDef(name='__init__', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='in_column', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Subscript(value=Name(id='List', ctx=Load()), slice=Name(id='str', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load()), ctx=Load())), arg(arg='inplace', annotation=Name(id='bool', ctx=Load())), arg(arg='out_column', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Name(id='str', ctx=Load()), ctx=Load())), arg(arg='with_centering', annotation=Name(id='bool', ctx=Load())), arg(arg='with_scaling', annotation=Name(id='bool', ctx=Load())), arg(arg='quantile_range', annotation=Subscript(value=Name(id='Tuple', ctx=Load()), slice=Tuple(elts=[Name(id='float', ctx=Load()), Name(id='float', ctx=Load())], ctx=Load()), ctx=Load())), arg(arg='unit_variance', annotation=Name(id='bool', ctx=Load())), arg(arg='mode', annotation=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='TransformMode', ctx=Load()), Name(id='str', ctx=Load())], ctx=Load()), ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=None), Constant(value=True), Constant(value=None), Constant(value=True), Constant(value=True), Tuple(elts=[Constant(value=25), Constant(value=75)], ctx=Load()), Constant(value=False), Constant(value='per-segment')]), body=[Expr(value=Constant(value='\n        Init RobustScalerPreprocess.\n\n        Parameters\n        ----------\n        in_column:\n            columns to be scaled, if None - all columns will be scaled.\n        inplace:\n            features are changed by scaled.\n        out_column:\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\n        with_centering:\n            if True, center the data before scaling.\n        with_scaling:\n            if True, scale the data to interquartile range.\n        quantile_range:\n            quantile range.\n        unit_variance:\n            If True, scale data so that normally distributed features have a variance of 1.\n\n            In general, if the difference between the x-values of q_max and q_min for a standard normal\n            distribution is greater than 1, the dataset will be scaled down. If less than 1,\n            the dataset will be scaled up.\n        mode:\n            "macro" or "per-segment", way to transform features over segments.\n\n            * If "macro", transforms features globally, gluing the corresponding ones for all segments.\n\n            * If "per-segment", transforms features for each segment separately.\n\n        Raises\n        ------\n        ValueError:\n            if incorrect mode given\n        ')), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='with_centering', ctx=Store())], value=Name(id='with_centering', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='with_scaling', ctx=Store())], value=Name(id='with_scaling', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='quantile_range', ctx=Store())], value=Name(id='quantile_range', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='unit_variance', ctx=Store())], value=Name(id='unit_variance', ctx=Load())), Expr(value=Call(func=Attribute(value=Call(func=Name(id='super', ctx=Load()), args=[], keywords=[]), attr='__init__', ctx=Load()), args=[], keywords=[keyword(arg='in_column', value=Name(id='in_column', ctx=Load())), keyword(arg='inplace', value=Name(id='inplace', ctx=Load())), keyword(arg='out_column', value=Name(id='out_column', ctx=Load())), keyword(arg='transformer', value=Call(func=Name(id='RobustScaler', ctx=Load()), args=[], keywords=[keyword(arg='with_centering', value=Attribute(value=Name(id='self', ctx=Load()), attr='with_centering', ctx=Load())), keyword(arg='with_scaling', value=Attribute(value=Name(id='self', ctx=Load()), attr='with_scaling', ctx=Load())), keyword(arg='quantile_range', value=Attribute(value=Name(id='self', ctx=Load()), attr='quantile_range', ctx=Load())), keyword(arg='unit_variance', value=Attribute(value=Name(id='self', ctx=Load()), attr='unit_variance', ctx=Load())), keyword(arg='copy', value=Constant(value=True))])), keyword(arg='mode', value=Name(id='mode', ctx=Load()))]))], decorator_list=[])], decorator_list=[]), ClassDef(name='MinMaxScalerTransform', bases=[Name(id='SklearnTransform', ctx=Load())], keywords=[], body=[Expr(value=Constant(value='Transform features by scaling each feature to a given range.\n\n    Uses :py:class:`sklearn.preprocessing.MinMaxScaler` inside.\n\n    Warning\n    -------\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\n    it uses information from the whole train part.\n    ')), FunctionDef(name='__init__', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='in_column', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Subscript(value=Name(id='List', ctx=Load()), slice=Name(id='str', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load()), ctx=Load())), arg(arg='inplace', annotation=Name(id='bool', ctx=Load())), arg(arg='out_column', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Name(id='str', ctx=Load()), ctx=Load())), arg(arg='feature_range', annotation=Subscript(value=Name(id='Tuple', ctx=Load()), slice=Tuple(elts=[Name(id='float', ctx=Load()), Name(id='float', ctx=Load())], ctx=Load()), ctx=Load())), arg(arg='clip', annotation=Name(id='bool', ctx=Load())), arg(arg='mode', annotation=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='TransformMode', ctx=Load()), Name(id='str', ctx=Load())], ctx=Load()), ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=None), Constant(value=True), Constant(value=None), Tuple(elts=[Constant(value=0), Constant(value=1)], ctx=Load()), Constant(value=True), Constant(value='per-segment')]), body=[Expr(value=Constant(value='\n        Init MinMaxScalerPreprocess.\n\n        Parameters\n        ----------\n        in_column:\n            columns to be scaled, if None - all columns will be scaled.\n        inplace:\n            features are changed by scaled.\n        out_column:\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\n        feature_range:\n            desired range of transformed data.\n        clip:\n            set to True to clip transformed values of held-out data to provided feature range.\n        mode:\n            "macro" or "per-segment", way to transform features over segments.\n\n            * If "macro", transforms features globally, gluing the corresponding ones for all segments.\n\n            * If "per-segment", transforms features for each segment separately.\n\n        Raises\n        ------\n        ValueError:\n            if incorrect mode given\n        ')), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='feature_range', ctx=Store())], value=Name(id='feature_range', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='clip', ctx=Store())], value=Name(id='clip', ctx=Load())), Expr(value=Call(func=Attribute(value=Call(func=Name(id='super', ctx=Load()), args=[], keywords=[]), attr='__init__', ctx=Load()), args=[], keywords=[keyword(arg='in_column', value=Name(id='in_column', ctx=Load())), keyword(arg='inplace', value=Name(id='inplace', ctx=Load())), keyword(arg='out_column', value=Name(id='out_column', ctx=Load())), keyword(arg='transformer', value=Call(func=Name(id='MinMaxScaler', ctx=Load()), args=[], keywords=[keyword(arg='feature_range', value=Attribute(value=Name(id='self', ctx=Load()), attr='feature_range', ctx=Load())), keyword(arg='clip', value=Attribute(value=Name(id='self', ctx=Load()), attr='clip', ctx=Load())), keyword(arg='copy', value=Constant(value=True))])), keyword(arg='mode', value=Name(id='mode', ctx=Load()))]))], decorator_list=[])], decorator_list=[]), ClassDef(name='MaxAbsScalerTransform', bases=[Name(id='SklearnTransform', ctx=Load())], keywords=[], body=[Expr(value=Constant(value='Scale each feature by its maximum absolute value.\n\n    Uses :py:class:`sklearn.preprocessing.MaxAbsScaler` inside.\n\n    Warning\n    -------\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\n    it uses information from the whole train part.\n    ')), FunctionDef(name='__init__', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='in_column', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Subscript(value=Name(id='List', ctx=Load()), slice=Name(id='str', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load()), ctx=Load())), arg(arg='inplace', annotation=Name(id='bool', ctx=Load())), arg(arg='out_column', annotation=Subscript(value=Name(id='Optional', ctx=Load()), slice=Name(id='str', ctx=Load()), ctx=Load())), arg(arg='mode', annotation=Subscript(value=Name(id='Union', ctx=Load()), slice=Tuple(elts=[Name(id='TransformMode', ctx=Load()), Name(id='str', ctx=Load())], ctx=Load()), ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=None), Constant(value=True), Constant(value=None), Constant(value='per-segment')]), body=[Expr(value=Constant(value='Init MinMaxScalerPreprocess.\n\n        Parameters\n        ----------\n        in_column:\n            columns to be scaled, if None - all columns will be scaled.\n        inplace:\n            features are changed by scaled.\n        out_column:\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\n        mode:\n            "macro" or "per-segment", way to transform features over segments.\n\n            * If "macro", transforms features globally, gluing the corresponding ones for all segments.\n\n            * If "per-segment", transforms features for each segment separately.\n\n        Raises\n        ------\n        ValueError:\n            if incorrect mode given\n        ')), Expr(value=Call(func=Attribute(value=Call(func=Name(id='super', ctx=Load()), args=[], keywords=[]), attr='__init__', ctx=Load()), args=[], keywords=[keyword(arg='in_column', value=Name(id='in_column', ctx=Load())), keyword(arg='inplace', value=Name(id='inplace', ctx=Load())), keyword(arg='out_column', value=Name(id='out_column', ctx=Load())), keyword(arg='transformer', value=Call(func=Name(id='MaxAbsScaler', ctx=Load()), args=[], keywords=[keyword(arg='copy', value=Constant(value=True))])), keyword(arg='mode', value=Name(id='mode', ctx=Load()))]))], decorator_list=[])], decorator_list=[]), Assign(targets=[Name(id='__all__', ctx=Store())], value=List(elts=[Constant(value='MaxAbsScalerTransform'), Constant(value='MinMaxScalerTransform'), Constant(value='RobustScalerTransform'), Constant(value='StandardScalerTransform')], ctx=Load()))], type_ignores=[])